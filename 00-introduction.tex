\chapter*{Introduction}
\addcontentsline{toc}{chapter}{Introduction}
\markboth{Introduction}{Introduction}
\label{chap:introduction}
%\minitoc

Evolutionary algorithms are an attractive alternative to gradient-based methods for the optimization of neural network parameters. Evolutionary strategies \cite{natural-evo-strat} estimate the gradient of the objective function but do not require a strict gradient definition, enabling their application to a variety of problems. The evolution of synaptic weights of a neural network has been demonstrated on a variety of tasks \cite{deep_neuroevo} and is competitive to state-of-the-art deep reinforcement learning methods such as Deep Q Networks \cite{human-lvl-control}. 

However there are many open questions in the application of neural networks. Direct encoding approaches which optimize each synaptic weight often struggle with high-dimensionality, which is required for convolutional neural networks with millions of parameters. Indirect encoding approaches which optimize a surrogate function which is then applied to determine neural network weights might not be able to reach specific maxima due to the limitations of the genetic encoding. Finally, some evolutionary approaches also optimize neural network structure in addition to or instead of synaptic weight optimization. 

Neural networks are often applied in supervised learning cases where data is plentiful and a strong error signal can be backpropogated through the network for each set of examples. Stochastic search methods such as evolutionary algorithms, which at best estimate the search space and are intended to optimize independent variables, are not an appropriate choice for supervised learning. However, when the learning signal is weak, such as in reinforcement learning, evolutionary methods can improve on gradient-based methods which must construct a differentiable approximation of the objective. The application domain of this internship is therefore games, which have a weak learning signal and sparse rewards; this is a domain where evolutionary algorithms are a good choice over other gradient-based methods.


In chapters \ref{chap:prolegomena} and \ref{chap:evo}, I will lay the bases of Reinforcement Learning, neuroevolution and evolutionary approaches as a first theoretical preamble. Chapter \ref{chap:dota} will describe the competition we entered aiming at developing an AI to play 1v1 games of Dota 2. In chapters \ref{chap:berl} and \ref{chap:neuroevo}, I will then introduce BERL.jl and NeuroEvolution.jl, two Julia libraries I developed to try and benchmark evolutionary RL algorithms. 
Finally, chapter \ref{chap:results} will summarize results encountered so far and present the leads for future work in this internship.


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "isae-report-template"
%%% End: 
