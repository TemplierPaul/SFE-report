% This file was created with JabRef 2.8.1.
% Encoding: UTF8
@misc{wilson2018positionalcgp,
    title={Positional Cartesian Genetic Programming},
    author={DG Wilson and Julian F. Miller and Sylvain Cussat-Blanc and Hervé Luga},
    year={2018},
    eprint={1810.04119},
    archivePrefix={arXiv},
    primaryClass={cs.NE}
}

@article{ha2017evolving,
  title   = "Evolving Stable Strategies",
  author  = "Ha, David",
  journal = "blog.otoro.net",
  year    = "2017",
  url     = "http://blog.otoro.net/2017/11/12/evolving-stable-strategies/"
}

@inproceedings{NEAT_1,
  title={Efficient evolution of neural network topologies},
  author={Stanley, Kenneth O and Miikkulainen, Risto},
  booktitle={Proceedings of the 2002 Congress on Evolutionary Computation. CEC'02 (Cat. No. 02TH8600)},
  volume={2},
  pages={1757--1762},
  year={2002},
  organization={IEEE}
}

@article{NEAT_2,
  title={Evolving neural networks through augmenting topologies},
  author={Stanley, Kenneth O and Miikkulainen, Risto},
  journal={Evolutionary computation},
  volume={10},
  number={2},
  pages={99--127},
  year={2002},
  publisher={MIT Press}
}

@article{CMAES-Atari,
   author = {Tim Salimans and Jonathan Ho and Xi Chen and Szymon Sidor and Ilya Sutskever},
   month = {3},
   title = {Evolution Strategies as a Scalable Alternative to Reinforcement Learning},
   url = {http://arxiv.org/abs/1703.03864},
   year = {2017},
}

@report{rtNEAT,
   abstract = {In most modern video games, character behavior is scripted; no matter how many times the player exploits a weakness, that weakness is never repaired. Yet if game characters could learn through interacting with the player, behavior could improve as the game is played, keeping it interesting. This paper introduces the real-time NeuroEvolution of Augmenting Topologies (rtNEAT) method for evolving increasingly complex artificial neural networks in real time, as a game is being played. The rtNEAT method allows agents to change and improve during the game. In fact, rtNEAT makes possible an entirely new genre of video games in which the player trains a team of agents through a series of customized exercises. To demonstrate this concept, the NeuroEvolving Robotic Operatives (NERO) game was built based on rtNEAT. In NERO, the player trains a team of virtual robots for combat against other players' teams. This paper describes results from this novel application of machine learning, and demonstrates that rtNEAT makes possible video games like NERO where agents evolve and adapt in real time. In the future, rtNEAT may allow new kinds of educational and training applications through interactive and adapting games.},
   author = {Kenneth O Stanley and Bobby D Bryant and Risto Miikkulainen},
   issue = {6},
   journal = {IEEE Transactions on Evolutionary Computation (Special Issue on Evolutionary Computation and Games)},
   title = {Real-Time Neuroevolution in the NERO Video Game},
   volume = {9},
   url = {http://nerogame.org},
   year = {2005},
}

@report{FS-NEAT,
   abstract = {Feature selection is the process of finding the set of inputs to a machine learning algorithm that will yield the best performance. Developing a way to solve this problem automatically would make current machine learning methods much more useful. Previous efforts to automate feature selection rely on expensive meta-learning or are applicable only when labeled training data is available. This paper presents a novel method called FS-NEAT which extends the NEAT neuroevolution method to automatically determine an appropriate set of inputs for the networks it evolves. By learning the network's inputs, topology, and weights simultaneously , FS-NEAT addresses the feature selection problem without relying on meta-learning or labeled data. Initial experiments in an autonomous car racing simulation demonstrate that FS-NEAT can learn better and faster than regular NEAT. In addition, the networks it evolves are smaller and require fewer inputs. Furthermore, FS-NEAT's performance remains robust even as the feature selection task it faces is made increasingly difficult.},
   author = {Shimon Whiteson and Peter Stone and Kenneth O Stanley and Risto Miikkulainen and Nate Kohl},
   keywords = {I26 [Artificial Intelligence]: Learning-Connectionism and neural nets General Terms Experimentation Keywords genetic algorithms,feature selection,neural networks},
   title = {Automatic Feature Selection in Neuroevolution},
   year = {2005},
}

@article{GP_anecdotes,
   abstract = {Biological evolution provides a creative fount of complex and subtle adaptations, often surprising the scientists who discover them. However, because evolution is an algorithmic process that transcends the substrate in which it occurs, evolution's creativity is not limited to nature. Indeed, many researchers in the field of digital evolution have observed their evolving algorithms and organisms subverting their intentions, exposing unrecognized bugs in their code, producing unexpected adaptations, or exhibiting outcomes uncannily convergent with ones in nature. Such stories routinely reveal creativity by evolution in these digital worlds, but they rarely fit into the standard scientific narrative. Instead they are often treated as mere obstacles to be overcome, rather than results that warrant study in their own right. The stories themselves are traded among researchers through oral tradition, but that mode of information transmission is inefficient and prone to error and outright loss. Moreover, the fact that these stories tend to be shared only among practitioners means that many natural scientists do not realize how interesting and lifelike digital organisms are and how natural their evolution can be. To our knowledge, no collection of such anecdotes has been published before. This paper is the crowd-sourced product of researchers in the fields of artificial life and evolutionary computation who have provided first-hand accounts of such cases. It thus serves as a written, fact-checked collection of scientifically important and even entertaining stories. In doing so we also present here substantial evidence that the existence and importance of evolutionary surprises extends beyond the natural world, and may indeed be a universal property of all complex evolving systems.},
   author = {Joel Lehman and Jeff Clune and Dusan Misevic and Christoph Adami and Lee Altenberg and Julie Beaulieu and Peter J. Bentley and Samuel Bernard and Guillaume Beslon and David M. Bryson and Patryk Chrabaszcz and Nick Cheney and Antoine Cully and Stephane Doncieux and Fred C. Dyer and Kai Olav Ellefsen and Robert Feldt and Stephan Fischer and Stephanie Forrest and Antoine Frénoy and Christian Gagné and Leni Le Goff and Laura M. Grabowski and Babak Hodjat and Frank Hutter and Laurent Keller and Carole Knibbe and Peter Krcah and Richard E. Lenski and Hod Lipson and Robert MacCurdy and Carlos Maestre and Risto Miikkulainen and Sara Mitri and David E. Moriarty and Jean-Baptiste Mouret and Anh Nguyen and Charles Ofria and Marc Parizeau and David Parsons and Robert T. Pennock and William F. Punch and Thomas S. Ray and Marc Schoenauer and Eric Shulte and Karl Sims and Kenneth O. Stanley and François Taddei and Danesh Tarapore and Simon Thibault and Westley Weimer and Richard Watson and Jason Yosinski},
   month = {3},
   title = {The Surprising Creativity of Digital Evolution: A Collection of Anecdotes from the Evolutionary Computation and Artificial Life Research Communities},
   url = {http://arxiv.org/abs/1803.03453},
   year = {2018},
}
@article{Dota2,
   abstract = {The capacity of genetic programming (GP) to evolve a 'hero' character in the Dota 2 video game is investigated. A reinforcement learning context is assumed in which the only input is a 320-dimensional state vector and performance is expressed in terms of kills and net worth. Minimal assumptions are made to initialize the GP game playing agents-evolution from a tabula rasa starting point-implying that: 1) the instruction set is not task specific; 2) end of game performance feedback reflects quantitive properties a player experiences ; 3) no attempt is made to impart game specific knowledge into GP, such as heuristics for improving navigation, minimizing partial observability, improving team work or prioritizing the protection of specific strategically important structures. In short, GP has to actively develop its own strategies for all aspects of the game. We are able to demonstrate competitive play with the built in game opponents assuming 1-on-1 competitions using the 'Shadow Fiend' hero. The single most important contributing factor to this result is the provision of external memory to GP. Without this, the resulting Dota 2 bots are not able to identify strategies that match those of the built-in game bot. CCS CONCEPTS • Computing methodologies → Reinforcement learning; Genetic programming.},
   author = {Robert J Smith and Malcolm I Heywood},
   doi = {10.1145/3321707.3321866},
   isbn = {9781450361118},
   keywords = {Coevolution,Dota 2,External Memory,Genetic programming,Partial Observability,Reinforcement learning},
   publisher = {ACM},
   title = {Evolving Dota 2 Shadow Fiend Bots using Genetic Programming with External Memory},
   url = {https://doi.org/10.1145/3321707.3321866},
   year = {2019},
}
@misc{GRN,
    title={Evolving Differentiable Gene Regulatory Networks},
    author={Dennis G Wilson and Kyle Harrington and Sylvain Cussat-Blanc and Hervé Luga},
    year={2018},
    eprint={1807.05948},
    archivePrefix={arXiv},
    primaryClass={cs.NE}
}
@report{HyperNEAT,
   abstract = {Research in neuroevolution, i.e. evolving artificial neural networks (ANNs) through evolutionary algorithms , is inspired by the evolution of biological brains. Because natural evolution discovered intelligent brains with billions of neurons and trillions of connections, perhaps neuroevolution can do the same. Yet while neuroevolution has produced successful results in a variety of domains, the scale of natural brains remains far beyond reach. This paper presents a method called Hypercube-based NeuroEvolution of Augmenting Topologies (HyperNEAT) that aims to narrow this gap. HyperNEAT employs an indirect encoding called connective Compositional Pattern Producing Networks (connective CPPNs) that can produce con-nectivity patterns with symmetries and repeating motifs by interpreting spatial patterns generated within a hypercube as connectivity patterns in a lower-dimensional space. The advantage of this approach is that it can exploit the geometry of the task by mapping its regularities onto the topology of the network, thereby shifting problem difficulty away from dimensionality to underlying problem structure. Furthermore, connective CPPNs can represent the same connectivity pattern at any resolution, allowing ANNs to scale to new numbers of inputs and outputs without further evolution. HyperNEAT is demonstrated through visual discrimination and food gathering tasks, including successful visual discrimination networks containing over eight million connections. The main conclusion is that the ability to explore the space of regular connectivity patterns opens up a new class of complex high-dimensional tasks to neuroevolution.},
   author = {Kenneth O Stanley and David D ' Ambrosio and Jason Gauci},
   issue = {2},
   journal = {Artificial Life journal},
   keywords = {CPPNs,Compositional Pattern Producing Networks,HyperNEAT,generative and developmental systems,indirect encoding,large-scale artificial neural networks},
   publisher = {MIT Press},
   title = {A Hypercube-Based Indirect Encoding for Evolving Large-Scale Neural Networks},
   volume = {15},
   year = {2009},
}

@article{CMAES-DL,
  title={CMA-ES for hyperparameter optimization of deep neural networks},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1604.07269},
  year={2016}
}

@article{CPPN,
   author = {Kenneth O. Stanley},
   title = {Compositional pattern producing networks: A novel abstraction of development},
}
@report{competitive_co-evolution,
   abstract = {Two major goals in machine learning are the discovery and improvement of solutions to complex problems. In this paper, we argue that complexification, i.e. the incremental elaboration of solutions through adding new structure, achieves both these goals. We demonstrate the power of complexification through the NeuroEvolution of Augmenting Topologies (NEAT) method, which evolves increasingly complex neural network architectures. NEAT is applied to an open-ended coevolutionary robot duel domain where robot controllers compete head to head. Because the robot duel domain supports a wide range of strategies, and because coevolution benefits from an escalating arms race, it serves as a suitable testbed for studying complexification. When compared to the evolution of networks with fixed structure , complexifying evolution discovers significantly more sophisticated strategies. The results suggest that in order to discover and improve complex solutions, evolution, and search in general, should be allowed to complexify as well as optimize.},
   author = {Kenneth O Stanley and Risto Miikkulainen},
   journal = {Journal of Artificial Intelligence Research},
   keywords = {Changes and compilation copyright © The American Association for Artificial Intelligence. All rights reserved.,Copyright © 2004 AI Access},
   pages = {63-100},
   title = {Competitive Coevolution through Evolutionary Complexification},
   volume = {21},
   year = {2004},
}
@article{Games_AI,
   abstract = {s Although one of the fundamental goals of AI is to understand and develop intelligent systems that have all the capabilities of humans, there is little active research directly pursuing this goal. We propose that AI for interactive computer games is an emerging application area in which this goal of human-level AI can successfully be pursued. Interactive computer games have increasingly complex and realistic worlds and increasingly complex and intelligent computer-controlled characters. In this article, we further motivate our proposal of using interactive computer games for AI research, review previous research on AI and games, and present the different game genres and the roles that human-level AI could play within these genres. We then describe the research issues and AI techniques that are relevant to each of these roles. Our conclusion is that interactive computer games provide a rich environment for incremental research on human-level AI. O ver the last 30 years, research in AI has fragmented into more and more specialized fields, working on more and more specialized problems, using more and more specialized algorithms. This approach has led to a long string of successes with important theoretical and practical advancements. However, these successes have made it easy for us to ignore our failure to make significant progress in building human-level AI systems. Human-level AI systems are the ones that you dreamed about when you first heard of AI: HAL from 2001, A Space Odyssey; DATA from Star Trek; or CP30 and R2D2 from Star Wars. They are smart enough to be both triumphant heroes and devious villains. They seamlessly integrate all the human-level capabilities: real-time response, robustness, autonomous intelligent interaction with their environment, planning, communication with natural language, com-monsense reasoning, creativity, and learning. If this is our dream, why isn't any progress being made? Ironically, one of the major reasons that almost nobody (see Brooks et al. [2000] for one high-profile exception) is working on this grand goal of AI is that current applications of AI do not need full-blown human-level AI. For almost all applications, the generality and adaptability of human thought is not needed-specialized, although more rigid and fragile, solutions are cheaper and easier to develop. Unfortunately, it is unclear whether the approaches that have been developed to solve specific problems are the right building blocks for creating human-level intelligence. The thesis of this article is that interactive computer games are the killer application for human-level AI. They are the application that will need human-level AI. Moreover, they can provide the environments for research on the right kinds of problem that lead to the type of incremental and integrative research needed to achieve human-level AI. Computer-Generated Forces Given that our personal goal is to build human-level AI systems, we have struggled to find the right application for our research that requires the breadth, depth, and flexibility of human-level intelligence. In 1991, we found computer-generated forces for large-scale distributed simulations as a potential application. Effective military training requires a complete battle space with tens if not hundreds or thousands of participants. The real world is too expensive and dangerous to use for continual training,},
   author = {John E Laird and Michael Van Lent},
   journal = {AI Magazine Volume 22 Number 2 (2001) (© AAAI)},
   title = {Human-Level AI's Killer Application Interactive Computer Games },
   year = {2001},
}

@article{Atari,
  author    = {Marc G. Bellemare and
               Yavar Naddaf and
               Joel Veness and
               Michael Bowling},
  title     = {The Arcade Learning Environment: An Evaluation Platform for General
               Agents},
  journal   = {CoRR},
  volume    = {abs/1207.4708},
  year      = {2012},
  url       = {http://arxiv.org/abs/1207.4708},
  archivePrefix = {arXiv},
  eprint    = {1207.4708},
  timestamp = {Mon, 13 Aug 2018 16:46:44 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1207-4708.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{agent57,
    title={Agent57: Outperforming the Atari Human Benchmark},
    author={Adrià Puigdomènech Badia and Bilal Piot and Steven Kapturowski and Pablo Sprechmann and Alex Vitvitskyi and Daniel Guo and Charles Blundell},
    year={2020},
    eprint={2003.13350},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{DQN,
    title={Playing Atari with Deep Reinforcement Learning},
    author={Volodymyr Mnih and Koray Kavukcuoglu and David Silver and Alex Graves and Ioannis Antonoglou and Daan Wierstra and Martin Riedmiller},
    year={2013},
    eprint={1312.5602},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@article{human-lvl-control,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{deep_neuroevo,
  author    = {Felipe Petroski Such and
               Vashisht Madhavan and
               Edoardo Conti and
               Joel Lehman and
               Kenneth O. Stanley and
               Jeff Clune},
  title     = {Deep Neuroevolution: Genetic Algorithms Are a Competitive Alternative
               for Training Deep Neural Networks for Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1712.06567},
  year      = {2017},
  url       = {http://arxiv.org/abs/1712.06567},
  archivePrefix = {arXiv},
  eprint    = {1712.06567},
  timestamp = {Mon, 13 Aug 2018 16:46:09 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1712-06567.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{BERL,
    author       = {Dennis Wilson},
    title        = {{BERL.lj: Benchmarking Evolutionary Reinforcement Learning}},
    url          = {https://github.com/d9w/BERL.jl}
    }
    
@inproceedings{CMA-ES,
  title={Adapting arbitrary normal mutation distributions in evolution strategies: The covariance matrix adaptation},
  author={Hansen, Nikolaus and Ostermeier, Andreas},
  booktitle={Proceedings of IEEE international conference on evolutionary computation},
  pages={312--317},
  year={1996},
  organization={IEEE}
}

@article{julia-lang,
author = {Bezanson, Jeff and Edelman, Alan and Karpinski, Stefan and Shah, Viral B.},
title = {Julia: A Fresh Approach to Numerical Computing},
journal = {SIAM Review},
volume = {59},
number = {1},
pages = {65-98},
year = {2017},
doi = {10.1137/141000671},

URL = { 
        https://doi.org/10.1137/141000671
    
},
eprint = { 
        https://doi.org/10.1137/141000671
    
}
}

@article{CGP,
  author    = {Dennis G. Wilson and
               Sylvain Cussat{-}Blanc and
               Herv{\'{e}} Luga and
               Julian F. Miller},
  title     = {Evolving simple programs for playing Atari games},
  journal   = {CoRR},
  volume    = {abs/1806.05695},
  year      = {2018},
  url       = {http://arxiv.org/abs/1806.05695},
  archivePrefix = {arXiv},
  eprint    = {1806.05695},
  timestamp = {Mon, 13 Aug 2018 16:46:45 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1806-05695.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{MapElites,
  author =    {Jean-Baptiste Mouret and Jeff Clune },
  title =     {Illuminating search spaces by mapping elites},
  year=       {2015},
  url=        "https://arxiv.org/pdf/1504.04909.pdf",
}
@misc{unet,
    title={U-Net: Convolutional Networks for Biomedical Image Segmentation},
    author={Olaf Ronneberger and Philipp Fischer and Thomas Brox},
    year={2015},
    eprint={1505.04597},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@misc{noisy-map-elites,
    title={Fast and stable MAP-Elites in noisy domains using deep grids},
    author={Manon Flageat and Antoine Cully},
    year={2020},
    eprint={2006.14253},
    archivePrefix={arXiv},
    primaryClass={cs.NE}
}

@ARTICLE{mdp,
    author = "Richard Bellman",
     title = "A Markovian Decision Process",
   journal = "Indiana Univ. Math. J.",
  fjournal = "Indiana University Mathematics Journal",
    volume = 6,
      year = 1957,
     issue = 4,
     pages = "679--684",
      issn = "0022-2518",
     coden = "IUMJAB",
   mrclass = "",
}

@misc{natural-evo-strat,
    title={Natural Evolution Strategies},
    author={Daan Wierstra and Tom Schaul and Tobias Glasmachers and Yi Sun and Jürgen Schmidhuber},
    year={2011},
    eprint={1106.4487},
    archivePrefix={arXiv},
    primaryClass={stat.ML}
}

@book{cleveralgos,
    author    = "Jason Brownlee",
    title     = "The \LaTeX\ Companion",
    year      = "1993",
    publisher = "Addison-Wesley",
    address   = "Reading, Massachusetts"
}

@article{sgd,
author = "Robbins, Herbert and Monro, Sutton",
doi = "10.1214/aoms/1177729586",
fjournal = "Annals of Mathematical Statistics",
journal = "Ann. Math. Statist.",
month = "09",
number = "3",
pages = "400--407",
publisher = "The Institute of Mathematical Statistics",
title = "A Stochastic Approximation Method",
url = "https://doi.org/10.1214/aoms/1177729586",
volume = "22",
year = "1951"
}

@ARTICLE{perceptron,
    author = {F. Rosenblatt},
    title = {The Perceptron: A Probabilistic Model for Information Storage and Organization in The Brain},
    journal = {Psychological Review},
    year = {1958},
    pages = {65--386}
}

@book{origin-of-species,
  title={The origin of species by means of natural selection: or, the preservation of favored races in the struggle for life},
  author={Darwin, Charles},
  year={1859}
}

@book{introduction-ga,
  title={An introduction to genetic algorithms},
  author={Mitchell, Melanie},
  year={1998},
  publisher={MIT press}
}

@ARTICLE{genetics,
    author = {Mendel, Gregor},
    title = {EXPERIMENTS IN PLANT HYBRIDIZATION},
    journal = {Psychological Review},
    year = {1865}
}

@inproceedings{intro-gp,
author = {O'Reilly, Una-May and Hemberg, Erik},
title = {Introduction to Genetic Programming},
year = {2019},
isbn = {9781450367486},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3319619.3323398},
doi = {10.1145/3319619.3323398},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
pages = {710–725},
numpages = {16},
location = {Prague, Czech Republic},
series = {GECCO '19}
}

@inproceedings{novelty-search-local-competition,
  title={Evolving a diversity of virtual creatures through novelty search and local competition},
  author={Lehman, Joel and Stanley, Kenneth O},
  booktitle={Proceedings of the 13th annual conference on Genetic and evolutionary computation},
  pages={211--218},
  year={2011}
}

@ARTICLE{quality-diversity,  
    author={A. {Cully} and Y. {Demiris}},  
    journal={IEEE Transactions on Evolutionary Computation},   title={Quality and Diversity Optimization: A Unifying Modular Framework},   
    year={2018},  
    volume={22},  
    number={2},  
    pages={245-259}
}

@inproceedings{novelty-search-theory,
  title={Novelty search: a theoretical perspective},
  author={Doncieux, Stephane and Laflaqui{\`e}re, Alban and Coninx, Alexandre},
  booktitle={Proceedings of the Genetic and Evolutionary Computation Conference},
  pages={99--106},
  year={2019}
}

@ARTICLE{novelty-only,  author={J. {Lehman} and K. O. {Stanley}},  journal={Evolutionary Computation},   title={Abandoning Objectives: Evolution Through the Search for Novelty Alone},   year={2011},  volume={19},  number={2},  pages={189-223},}

@inproceedings{tpg,
  title     = {Emergent Tangled Program Graphs in Multi-Task Learning},
  author    = {Stephen Kelly and Malcolm Heywood},
  booktitle = {Proceedings of the Twenty-Seventh International Joint Conference on
               Artificial Intelligence, {IJCAI-18}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},             
  pages     = {5294--5298},
  year      = {2018},
  month     = {7},
  doi       = {10.24963/ijcai.2018/740},
  url       = {https://doi.org/10.24963/ijcai.2018/740},
}

@InProceedings{grammatical-evo,
author = "Conor Ryan and J. J. Collins and Michael O'Neill",
title = "Grammatical Evolution: Evolving Programs for an Arbitrary Language",
booktitle = "Proceedings of the First European Workshop on Genetic Programming",
year = "1998",
editor = "Wolfgang Banzhaf and Riccardo Poli and Marc Schoenauer and Terence C. Fogarty",
volume = "1391",
series = "LNCS",
pages = "83--96",
address = "Paris",
publisher_address = "Berlin",
month = "14-15 " # apr,
publisher = "Springer-Verlag",
keywords = "genetic algorithms, genetic programming, grammatical evolution",
ISBN = "3-540-64360-5",
URL = "http://www.lania.mx/~ccoello/eurogp98.ps.gz",
URL = "http://citeseer.ist.psu.edu/ryan98grammatical.html",
DOI = "doi:10.1007/BFb0055930",
size = "14 pages",
abstract = "We describe a Genetic Algorithm that can evolve complete programs. Using a variable length linear genome to govern how a Backus Naur Form grammar definition is mapped to a program, expressions and programs of arbitrary complexity may be evolved. Other automatic programming methods are described, before our system, Grammatical Evolution, is applied to a symbolic regression problem.",
notes = "EuroGP'98",
affiliation = "University of Limerick Dept. Of Computer Science and Information Systems Ireland Ireland",
}

@misc{neuromodulation,
    title={Neuromodulated Learning in Deep Neural Networks},
    author={Dennis G Wilson and Sylvain Cussat-Blanc and Hervé Luga and Kyle Harrington},
    year={2018},
    eprint={1812.03365},
    archivePrefix={arXiv},
    primaryClass={cs.NE}
}

@misc{ wiki:cmaes,
    author = "{Wikipedia contributors}",
    title = "CMA-ES --- {Wikipedia}{,} The Free Encyclopedia",
    year = "2020",
    howpublished = "\url{https://en.wikipedia.org/w/index.php?title=CMA-ES&oldid=967047119}",
    note = "[Online; accessed 20-August-2020]"
  }
  
  @misc{ wiki:dota,
    author = "{Wikipedia contributors}",
    title = "Dota 2 --- {Wikipedia}{,} The Free Encyclopedia",
    year = "2020",
    howpublished = "\url{https://en.wikipedia.org/w/index.php?title=Dota_2&oldid=966599163}",
    note = "[Online; accessed 20-August-2020]"
  }
  
@article{ann-graph,
    author = {Bre, Facundo and Gimenez, Juan and Fachinotti, Víctor},
    year = {2017},
    month = {11},
    pages = {},
    title = {Prediction of wind pressure coefficients on building surfaces using Artificial Neural Networks},
    volume = {158},
    journal = {Energy and Buildings},
    doi = {10.1016/j.enbuild.2017.11.045}
}

@inproceedings{GP-benchmark,
  title={Genetic programming needs better benchmarks},
  author={McDermott, James and White, David R and Luke, Sean and Manzoni, Luca and Castelli, Mauro and Vanneschi, Leonardo and Jaskowski, Wojciech and Krawiec, Krzysztof and Harper, Robin and De Jong, Kenneth and others},
  booktitle={Proceedings of the 14th annual conference on Genetic and evolutionary computation},
  pages={791--798},
  year={2012}
}